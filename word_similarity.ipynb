{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !yes|pip uninstall spacy\n",
        "# !pip install spacy==3.1.1\n",
        "# !python -m spacy info\n",
        "import spacy\n",
        "print(spacy.__version__)  # 3.1.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y12SmsipDGQe",
        "outputId": "3f1f3bdc-4580-4eae-ae85-c04955e4059e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!yes | pip uninstall spacy\n",
        "\n",
        "!python -m spacy info\n",
        "import spacy\n",
        "print(spacy.__version__)  # 3.1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a95NP5AH6HJ",
        "outputId": "a13ec179-688e-489c-e2e0-41fad3554448"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-08 12:57:38.910386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.5.2                         \n",
            "Location         /usr/local/lib/python3.10/dist-packages/spacy\n",
            "Platform         Linux-5.15.107+-x86_64-with-glibc2.31\n",
            "Python version   3.10.11                       \n",
            "Pipelines        en_core_web_sm (3.5.0)        \n",
            "\n",
            "3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "!yes|pip uninstall spacy-transformers\n",
        "!pip install spacy-transformers\n",
        "\n",
        "LANG = \"ITA\" # \"ENG\" or \"ITA\"\n",
        "\n",
        "if LANG == \"ITA\":\n",
        "  !python -m spacy download it_core_news_md\n",
        "  nlp = spacy.load(\"it_core_news_md\")\n",
        "  import it_core_news_md\n",
        "  pass\n",
        "elif LANG == \"ENG\":\n",
        "  !python -m spacy download en_core_web_lg --force\n",
        "  nlp = spacy.load(\"en_core_web_lg\")\n",
        "  import en_core_web_lg\n",
        "  nlp = en_core_web_lg.load()\n",
        "  pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh7uxzhh28bA",
        "outputId": "1580c84e-cc7c-4f41-8c38-bf467facfcbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping spacy-transformers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy-transformers\n",
            "  Downloading spacy_transformers-1.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.8/190.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<4.0.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (1.22.4)\n",
            "Collecting transformers<4.30.0,>=3.4.0 (from spacy-transformers)\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (2.4.6)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers)\n",
            "  Downloading spacy_alignments-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.0->spacy-transformers) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->spacy-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->spacy-transformers) (16.0.5)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers<4.30.0,>=3.4.0->spacy-transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.30.0,>=3.4.0->spacy-transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.30.0,>=3.4.0->spacy-transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<4.30.0,>=3.4.0->spacy-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers<4.30.0,>=3.4.0->spacy-transformers) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.5.0->spacy-transformers) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.5.0->spacy-transformers) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.5.0->spacy-transformers) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.5.0->spacy-transformers) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy-transformers) (1.3.0)\n",
            "Installing collected packages: tokenizers, spacy-alignments, huggingface-hub, transformers, spacy-transformers\n",
            "Successfully installed huggingface-hub-0.15.1 spacy-alignments-0.9.0 spacy-transformers-1.2.4 tokenizers-0.13.3 transformers-4.29.2\n",
            "2023-06-08 12:58:10.478687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting it-core-news-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_md-3.5.0/it_core_news_md-3.5.0-py3-none-any.whl (42.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->it-core-news-md==3.5.0) (2.1.2)\n",
            "Installing collected packages: it-core-news-md\n",
            "Successfully installed it-core-news-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import spacy_transformers\n",
        "import numpy as np\n",
        "\n",
        "doc = nlp(\"Frase italiana.\")\n",
        "\n",
        "print([(w.text, w.pos_) for w in doc])\n",
        "print(len(nlp.vocab))"
      ],
      "metadata": {
        "id": "jW8J5k-3mgb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290f8786-aad5-46b7-d643-360d9fb7d8d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Frase', 'NOUN'), ('italiana', 'ADJ'), ('.', 'PUNCT')]\n",
            "383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "word1 = nlp('nero')\n",
        "word2 = nlp('bianco')\n",
        "\n",
        "similarity = word1.similarity(word2)\n",
        "print(f'{word1} ~= {word2} {similarity}') # 0.835\n",
        "\n",
        "print(len(nlp.vocab.strings))\n",
        "list(sorted(random.choices(list(nlp.vocab.strings), k=10)))"
      ],
      "metadata": {
        "id": "nw2-AxkkmO9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce2120d-f34e-48ee-d6ab-969fccc1cdc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nero ~= bianco 0.8355581480087845\n",
            "681944\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['357/1997',\n",
              " 'Foppe',\n",
              " 'Mathematics',\n",
              " 'Moraldo',\n",
              " 'RomaRarità',\n",
              " 'Tree',\n",
              " 'acra',\n",
              " 'korugar',\n",
              " 'migliorandolo',\n",
              " 'tissi']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import jit\n",
        "\n",
        "@jit(nopython=True)\n",
        "def cosine_similarity_numba(u:np.ndarray, v:np.ndarray):\n",
        "    assert(u.shape[0] == v.shape[0])\n",
        "    uv = 0\n",
        "    uu = 0\n",
        "    vv = 0\n",
        "    for i in range(u.shape[0]):\n",
        "        uv += u[i]*v[i]\n",
        "        uu += u[i]*u[i]\n",
        "        vv += v[i]*v[i]\n",
        "    cos_theta = 1\n",
        "    if uu != 0 and vv != 0:\n",
        "        cos_theta = uv/np.sqrt(uu*vv)\n",
        "    return cos_theta"
      ],
      "metadata": {
        "id": "1w7vaiY2p0z1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar(word, topn=5, reverse=True):\n",
        "  word = nlp.vocab[str(word)]\n",
        "  queries = [\n",
        "      w for w in nlp.vocab \n",
        "      if np.count_nonzero(w.vector)\n",
        "  ]\n",
        "\n",
        "  by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=reverse)\n",
        "  return [(w.lower_,w.similarity(word)) for w in by_similarity[:topn+1] if w.lower_ != word.lower_]\n",
        "\n",
        "similar = most_similar(\"salume\", topn=3)\n",
        "print(similar)\n",
        "\n",
        "\n",
        "dir(nlp.vocab[\"king\"])\n",
        "nlp.vocab[\"king\"].has_vector\n",
        "nlp"
      ],
      "metadata": {
        "id": "8KubftWNp1g1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34dd4dac-34d6-46cf-f0a6-459e47dd5632"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('caserecci', 1.0), ('norcini', 1.0), ('salumieri', 1.0), ('casarecci', 1.0)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.it.Italian at 0x7f57ecb02320>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar2(word, topn=5, reverse=True):\n",
        "  word = nlp.vocab[str(word)]\n",
        "  queries = [\n",
        "      w for w in nlp.vocab \n",
        "      if np.count_nonzero(w.vector)\n",
        "  ]\n",
        "\n",
        "  by_similarity = sorted(queries, key=lambda w: cosine_similarity_numba(word.vector, w.vector), reverse=reverse)\n",
        "  return [(w.lower_,w.similarity(word)) for w in by_similarity[:topn+1] if w.lower_ != word.lower_]\n",
        "\n",
        "similar = most_similar2(\"salume\", topn=3)\n",
        "print(similar)\n",
        "\n",
        "\n",
        "dir(nlp.vocab[\"king\"])\n",
        "nlp.vocab[\"king\"].has_vector\n",
        "nlp"
      ],
      "metadata": {
        "id": "ayaGyDQsL96f",
        "outputId": "fe64157f-9601-43a5-a103-55f179f3367f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('caserecci', 1.0), ('norcini', 1.0), ('salumieri', 1.0), ('casarecci', 1.0)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.it.Italian at 0x7f57ecb02320>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# constansts\n",
        "\n",
        "START_WORD_LENGTHS = [4,5,6]\n",
        "\n",
        "MIN_WORD_LENGTH = 3\n",
        "MAX_WORD_LENGTH = 9\n",
        "\n",
        "NUM_STEPS = 8\n",
        "MIN_STEPS = 5\n",
        "\n"
      ],
      "metadata": {
        "id": "iHLr2i4jGyoQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Created on Feb 7, 2013\n",
        "\n",
        "@author: olegs\n",
        "'''\n",
        "\n",
        "ROMAN_CONSTANTS = (\n",
        "            ( \"\", \"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\" ),\n",
        "            ( \"\", \"X\", \"XX\", \"XXX\", \"XL\", \"L\", \"LX\", \"LXX\", \"LXXX\", \"XC\" ),\n",
        "            ( \"\", \"C\", \"CC\", \"CCC\", \"CD\", \"D\", \"DC\", \"DCC\", \"DCCC\", \"CM\" ),\n",
        "            ( \"\", \"M\", \"MM\", \"MMM\", \"\",   \"\",  \"-\",  \"\",    \"\",     \"\"   ),\n",
        "        )\n",
        "\n",
        "ROMAN_SYMBOL_MAP = dict(I=1, V=5, X=10, L=50, C=100, D=500, M=1000)\n",
        "\n",
        "CUTOFF = 4000\n",
        "BIG_DEC = 2900\n",
        "BIG_ROMAN = \"MMCM\"\n",
        "ROMAN_NOUGHT = \"nulla\"\n",
        "\n",
        "def digits(num):\n",
        "    if num < 0:\n",
        "        raise Exception('range error: negative numbers not supported')\n",
        "    if num % 1 != 0.0:\n",
        "        raise Exception('floating point numbers not supported')\n",
        "    res = []\n",
        "    while num > 0:\n",
        "        res.append(num % 10)\n",
        "        num //= 10\n",
        "    return res\n",
        "\n",
        "def toString(num, emptyZero=False):\n",
        "    if num < CUTOFF:\n",
        "        digitlist = digits(num)\n",
        "        if digitlist:\n",
        "            res = reversed([ ROMAN_CONSTANTS[order][digit] for order, digit in enumerate(digitlist) ])\n",
        "            return \"\".join(res)\n",
        "        else:\n",
        "            return \"\" if emptyZero else ROMAN_NOUGHT \n",
        "    else:\n",
        "        if num % 1 != 0.0:\n",
        "            raise Exception('floating point numbers not supported')\n",
        "        # For numbers over or equal the CUTOFF, the remainder of division by 2900\n",
        "        # is represented as above, prepended with the multiples of MMCM (2900 in Roman),\n",
        "        # which guarantees no more than 3 repetitive Ms.\n",
        "        return BIG_ROMAN * (num // BIG_DEC) + toString(num % BIG_DEC, emptyZero=True)\n",
        "\n",
        "def parse(numeral):\n",
        "    numeral = numeral.upper()\n",
        "    result = 0\n",
        "\n",
        "    lastVal = 0\n",
        "    lastCount = 0\n",
        "    subtraction = False\n",
        "    for symbol in numeral[::-1]:\n",
        "        value = ROMAN_SYMBOL_MAP.get(symbol)\n",
        "        if not value:\n",
        "            return False\n",
        "        if lastVal == 0:\n",
        "            lastCount = 1\n",
        "            lastVal = value\n",
        "        elif lastVal == value:\n",
        "            lastCount += 1\n",
        "            # exceptions\n",
        "        else:\n",
        "            result += (-1 if subtraction else 1) * lastVal * lastCount\n",
        "            subtraction = lastVal > value\n",
        "            lastCount = 1\n",
        "            lastVal = value\n",
        "    \n",
        "    result = result + (-1 if subtraction else 1) * lastVal * lastCount\n",
        "    return True"
      ],
      "metadata": {
        "id": "ECs8D5PzG4G1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "dictionaryFileName = 'assets/dictionary_FULL_IT.txt'\n",
        "dictionaryFileName = 'assets/Ita.txt'\n",
        "\n",
        "    \n",
        "def normalizeWord(word):\n",
        "    return word.strip().upper()\n",
        "    \n",
        "LOAD_FROM_URL = True\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "lines = []\n",
        "if LOAD_FROM_URL:\n",
        "    baseUrl = 'https://azrafe7.github.io/'\n",
        "    f = requests.get(baseUrl + dictionaryFileName)\n",
        "    lines = f.text.splitlines()\n",
        "else:\n",
        "    with open(dictionaryFileName) as f:\n",
        "        lines = f.read().splitlines()\n",
        "\n",
        "filteredWords = []\n",
        "for line in lines:\n",
        "    word = normalizeWord(line)\n",
        "    length = len(word)\n",
        "    if length >= MIN_WORD_LENGTH and length <= MAX_WORD_LENGTH and not parse(word):\n",
        "        filteredWords.append(word)\n",
        "\n",
        "print(\"Dictionary loaded in {0:.2f}s\".format(time.time() - t0))\n",
        "\n",
        "print('{0}/{1}'.format(len(filteredWords), len(lines)))\n",
        "\n",
        "print(filteredWords[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzYtS2s6G43t",
        "outputId": "c766204e-ac35-4732-eff1-44b2c35b5efe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary loaded in 0.87s\n",
            "401123/710993\n",
            "['AALENIANA', 'AALENIANE', 'AALENIANI', 'AALENIANO', 'ABABUA', 'ABACA', 'ABACETI', 'ABACETO', 'ABACHI', 'ABACHISTA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w in filteredWords:\n",
        "  nlp.vocab[w.lower()]"
      ],
      "metadata": {
        "id": "hMWMScsVHKtd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "word = 'perche'\n",
        "\n",
        "print(nlp.vocab[word].similarity(nlp.vocab['lupo']))\n",
        "\n",
        "# t0 = time.time()\n",
        "# similars = most_similar(word)\n",
        "# print('{0:.2f}s'.format(time.time() - t0))\n",
        "# display(similars)\n",
        "\n",
        "t0 = time.time()\n",
        "similars2 = most_similar2(word, reverse=True)\n",
        "print('{0:.2f}s'.format(time.time() - t0))\n",
        "display(similars2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "skJDNdhFnRhM",
        "outputId": "03e535d9-5799-4b3c-f5ec-cb0654fbd4b6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08700957894325256\n",
            "2.23s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('percio', 1.0),\n",
              " ('ergo', 0.8334516882896423),\n",
              " ('perché', 0.7591810822486877),\n",
              " ('cioe', 0.7424476146697998),\n",
              " ('pero', 0.7424476146697998)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'-ci' in nlp.vocab\n",
        "#[x.text for x in nlp.vocab]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI6tOcTQJxp2",
        "outputId": "dbff5c1b-f477-41d7-9721-372f78140c52"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = nlp.vocab['chaos']\n",
        "sorted([x.text for x in nlp.vocab])\n",
        "len([x.text for x in nlp.vocab])\n"
      ],
      "metadata": {
        "id": "PmeB5Hg0qECk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "parser = spacy.load(\"en_core_web_md\")\n"
      ],
      "metadata": {
        "id": "oze69EFDtDoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = u\"dog\"\n",
        "nasa = parser.vocab[word]\n",
        "\n",
        "# cosine similarity\n",
        "cosine = lambda v1, v2: dot(v1, v2) / (norm(v1) * norm(v2))\n",
        "\n",
        "# gather all known words, take only the lowercased versions\n",
        "allWords = list({w for w in parser.vocab if w.has_vector and w.orth_.islower() and w.is_alpha and w.lower_ != word})\n",
        "\n",
        "# sort by similarity to NASA\n",
        "allWords.sort(key=lambda w: cosine(w.vector, nasa.vector))\n",
        "allWords.reverse()\n",
        "print(f\"Top 10 most similar words to {word}:\")\n",
        "for word in allWords[:20]:\n",
        "    print(word.orth_, cosine(nasa.vector, word.vector))\n",
        "\n",
        "[w.text for w in allWords]"
      ],
      "metadata": {
        "id": "Cs9fQutVuU5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def replace_synonyms(text):\n",
        "    doc = nlp(text)\n",
        "    new_doc = []\n",
        "    for token in doc:\n",
        "        print(token.has_vector, token.pos_)\n",
        "        if token.has_vector and token.pos_ in [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\", \"PROPN\"]:\n",
        "            synonyms = [t for t in nlp.vocab if t.has_vector and t.similarity(token) > 0.2 and t.text != token.text]\n",
        "            if synonyms:\n",
        "                print(token.text, [s.text for s in synonyms])\n",
        "                new_token = random.choice(synonyms)\n",
        "                new_doc.append(new_token.text)\n",
        "            else:\n",
        "                new_doc.append(token.text)\n",
        "        else:\n",
        "            new_doc.append(token.text)\n",
        "    return \" \".join(new_doc)\n",
        "\n",
        "text = \"king key chain coffee water blind door nasa\"\n",
        "synonym_replaced_text = replace_synonyms(text)\n",
        "print(synonym_replaced_text)\n"
      ],
      "metadata": {
        "id": "wAZn5veRFUQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}